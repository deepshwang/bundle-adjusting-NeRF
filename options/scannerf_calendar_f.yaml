wandb: true
project: scannerf-v4
model: scannerf
max_iter: 400000                                            # train to maximum number of iterations
# Desired image size
H: 540
W: 960
yaml:

freq:                                                       # periodic actions during training
    scalar: 20                                             # log losses and scalar states (every N iterations)
    vis: 5000                                               # visualize results (every N iterations)
    val: 5000                                               # validate on val set (every N iterations)
    ckpt: 5000                                              # save checkpoint (every N iterations)

group:                                                      # name of experiment group
name:                                                       # name of experiment run
seed: 0                                                     # seed number (for both numpy and pytorch)
gpu: 2                                                      # GPU index number
cpu: false                                                  # run only on CPU (not supported now)
load:                                                       # load checkpoint from filename
resume: false                                               # resume training (true for latest checkpoint, or number for specific epoch number)
output_root: output                                         # root path for output files (checkpoints and results)

scannerf:
    N_obj: 1                                                # Number of foreground object as a prior
    N_block: 10                                             # Number of cascadal block steps for CFT

data:                                                       # data options
    dataset: static_blender                                 # dataset name
    scene: calendar                                         # scene name
    raw_image_size: [2160, 3840]                            # input image sizes [height,width]
    num_workers: 4                                          # number of parallel workers for data loading
    preload: true                                           # preload the entire dataset into the memory
    bgcolor: 1                                              # background color (Blender only)
    val_sub: 4                                              # consider a subset of N validation samples
    root:                                                   # root path to dataset
    augment: {}                                             # data augmentation (training only)
        # rotate:                                           # random rotation
        # brightness: # 0.2                                 # random brightness jitter
        # contrast: # 0.2                                   # random contrast jitter
        # saturation: # 0.2                                 # random saturation jitter
        # hue: # 0.1                                        # random hue jitter
        # hflip: # True                                     # random horizontal flip
    center_crop:                                            # center crop the image by ratio


arch:
    dim_latent: 256                                         # latent code dimension
    layers_feat: [null,256,256,256,256,256,256,256,256]     # hidden layers for feature/density MLP
    layers_rgb: [null,128,3]                                # hidden layers for color MLP
    skip: [4]                                               # skip connections
    posenc:                                                 # positional encoding
        L_3D: 10                                            # number of bases (3D point)
        L_view: 4                                           # number of bases (viewpoint)
        L_pose: 4
    density_activ: relu                                     # activation function for output volume density
    tf_init: true                                           # initialize network weights in TensorFlow style


nerf:                                                       # NeRF-specific options
    view_dep: true                                          # condition MLP on viewpoint
    depth:                                                  # depth-related options
        param: metric                                       # depth parametrization (for sampling along the ray)
        range: [0.2,2]                                        # near/far bounds for depth sampling
    sample_intvs: 128                                       # number of samples
    sample_intvs_fine: 64                                   # number of samples for the fine NeRF
    sample_stratified: true                                 # stratified sampling
    fine_sampling: true                                     # hierarchical sampling with another NeRF
    rand_rays: 32                                          # number of random rays for each step
    val_rand_rays: 1024                                     # Number of rays for visual validations
    density_noise_reg:                                      # Gaussian noise on density output as regularization
    setbg_opaque: false                                     # fill transparent rendering with known background color (Blender only)


camera:                                                     # camera options
    focal: 2860.2                                           # Focal length
    noise: 0.15                                             # synthetic perturbations on the camera poses (Blender only)
    model: perspective                                      # type of camera model
    ndc: false                                              # reparametrize as normalized device coordinates (NDC)

optim:                                                      # optimization options
    algo: Adam                                              # optimizer (see PyTorch doc)

    lr: 5.e-4                                               # learning rate (main)
    lr_end: 1.e-4                                           # terminal learning rate (only used with sched.type=ExponentialLR)
    sched:                                                  # learning rate scheduling options
        type: ExponentialLR                                 # scheduler (see PyTorch doc)
        gamma:

    lr_pose: 1.e-3                                          # learning rate of object poses
    lr_pose_end: 1.e-5                                      # terminal learning rate of camera poses (only used with sched_pose.type=ExponentialLR)
    warmup_pose:                                            # linear warmup of the pose learning rate (N iterations)
    sched_pose:                                             # learning rate scheduling options
        type: ExponentialLR                                 # scheduler (see PyTorch doc)
        gamma:                                              # decay rate (can be empty if lr_pose_end were specified)
#    test_photo: true                                        # test-time photometric optimization for evaluation
#    test_iter: 100                                          # number of iterations for test-time optimization

    lr_latent: 1.e-3
    lr_latent_end: 1.e-5
    sched_latent:
        type: ExponentialLR
        gamma:


loss_weight:                                                # loss weights (in log scale)
    render: 0                                               # RGB rendering loss
    render_fine: 0                                          # RGB rendering loss (for fine NeRF)

                                            # decay rate (can be empty if lr_end were specified)

trimesh:                                                    # options for marching cubes to extract 3D mesh
    res: 128                                                # 3D sampling resolution
    range: [-1.2,1.2]                                       # 3D range of interest (assuming same for x,y,z)
    thres: 25.                                              # volume density threshold for marching cubes
    chunk_size: 16384                                       # chunk size of dense samples to be evaluated at a time

barf_c2f:                                                   # coarse-to-fine scheduling on positional encoding

viz:
    sample_image_idx: [1, 5, 8]
